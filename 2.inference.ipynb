{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  6 21:10:54 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 41%   44C    P8    12W / 280W |  11335MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 41%   43C    P8     5W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 40%   55C    P2    59W / 280W |  24074MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 41%   46C    P8    13W / 280W |  24074MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "32\n",
      "Fri Aug  6 21:10:55 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 41%   44C    P8    13W / 280W |  11335MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 41%   43C    P8     5W / 280W |      3MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 41%   55C    P2    59W / 280W |  24074MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 41%   46C    P8    14W / 280W |  24074MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "True\n",
      "1\n",
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "# gpu status\n",
    "!nvidia-smi\n",
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "# !pip install tensorboard==1.15\n",
    "!nvidia-smi\n",
    "gpus= \"1\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus;\n",
    "    \n",
    "import torch\n",
    "gpu_count = torch.cuda.device_count()\n",
    "if gpu_count >=1:\n",
    "    torch.multiprocessing.set_start_method('spawn')\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(gpu_count)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "import torch\n",
    "import glob\n",
    "net = train.SegModel(data_dir='DRIVE',project='Retina',net='waveletunet_r2',net_inputch=3,net_outputch=3).cuda()\n",
    "\n",
    "# # PATH = 'logs/workspace-segment_/2appvswy/checkpoints/'\n",
    "# PATH = 'logs/Retina/2sq6hu4k/checkpoints/'\n",
    "# FILE = glob.glob(PATH+'*.ckpt')\n",
    "# print(FILE,'\\n',FILE[-1])\n",
    "# weight = torch.load(FILE[-1])\n",
    "# # weight = torch.load('NetNone_Lossboundaryce_Normgroup_Prefixmanet_b7_2class_.pt')\n",
    "\n",
    "# net.load_state_dict(weight['state_dict'])\n",
    "# # net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 128, 128])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= torch.rand(2,3,128,128).cuda()\n",
    "b = net(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataset = datasets.dataset('DRIVE','train',adaptive_hist_range=True)\n",
    "# train_dataset = datasets.dataset('DRIVE','train',adaptive_hist_range=False)\n",
    "train_loader = DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x = batch['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.imshow(x[0].permute(1,2,0))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.imshow(x[0].permute(1,2,0))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "# !pip install -r requirements.txt --user --quiet -U\n",
    "!pip uninstall torch -y\n",
    "!pip install torch==1.8.0\n",
    "# !apt updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt update\n",
    "# !sudo apt install libgl1-mesa-glx ffmpeg libsm6 libxext6 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log into weight and bias, if error occurs, please reset your jupyter kernal\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo rm -r logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls logs/Retina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py --project Retina \\\n",
    "                                        --data_dir ../Retina/dataset/DRIVE \\\n",
    "                                        --data_module dataset \\\n",
    "                                        --net waveletunet_r2 \\\n",
    "                                        --net_inputch 3 \\\n",
    "                                        --net_outputch 3 \\\n",
    "                                        --net_norm batch \\\n",
    "                                        --lossfn BoundaryCELoss \\\n",
    "                                        --precision 16 \\\n",
    "                                        --data_patchsize 128_128 \\\n",
    "                                        --batch_size 24 \\\n",
    "                                        --lr 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sweep using sweep.yaml\n",
    "!python -m wandb sweep sweep.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run sweeps\n",
    "# !CUDA_VISIBLE_DEVICES=0 python -m wandb agent [your_sweep_address]\n",
    "!CUDA_VISIBLE_DEVICES=0 python -m wandb agent keewonshin/Retina/rdzpb4mr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
