{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4837bf",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0a63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "!pip install -r requirements.txt --user --upgrade --quiet -U\n",
    "# !apt updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70cf726a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fil_finder astropy==4.3.1 typing \n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "import torch\n",
    "    \n",
    "from fil_finder import FilFinder2D\n",
    "import astropy.units as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59f601ca-f4bc-4e10-89bd-141970754479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Optional, Sequence, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from monai.networks.blocks import Convolution, UpSample\n",
    "from monai.networks.layers.factories import Conv, Pool\n",
    "from monai.utils import deprecated_arg, ensure_tuple_rep\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class NLBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, mode='embedded', \n",
    "                 dimension=3, bn_layer=True):\n",
    "        \"\"\"Implementation of Non-Local Block with 4 different pairwise functions but doesn't include subsampling trick\n",
    "        args:\n",
    "            in_channels: original channel size (1024 in the paper)\n",
    "            inter_channels: channel size inside the block if not specifed reduced to half (512 in the paper)\n",
    "            mode: supports Gaussian, Embedded Gaussian, Dot Product, and Concatenation\n",
    "            dimension: can be 1 (temporal), 2 (spatial), 3 (spatiotemporal)\n",
    "            bn_layer: whether to add batch norm\n",
    "        \"\"\"\n",
    "        super(NLBlockND, self).__init__()\n",
    "\n",
    "        assert dimension in [1, 2, 3]\n",
    "        \n",
    "        if mode not in ['gaussian', 'embedded', 'dot', 'concatenate']:\n",
    "            raise ValueError('`mode` must be one of `gaussian`, `embedded`, `dot` or `concatenate`')\n",
    "            \n",
    "        self.mode = mode\n",
    "        self.dimension = dimension\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        # the channel size is reduced to half inside the block\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "        \n",
    "        # assign appropriate convolutional, max pool, and batch norm layers for different dimensions\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "            bn = nn.BatchNorm3d\n",
    "        elif dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "            bn = nn.BatchNorm2d\n",
    "        else:\n",
    "            conv_nd = nn.Conv1d\n",
    "            max_pool_layer = nn.MaxPool1d(kernel_size=(2))\n",
    "            bn = nn.BatchNorm1d\n",
    "\n",
    "        # function g in the paper which goes through conv. with kernel size 1\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "\n",
    "        # add BatchNorm layer after the last conv layer\n",
    "        if bn_layer:\n",
    "            self.W_z = nn.Sequential(\n",
    "                    conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1),\n",
    "                    bn(self.in_channels)\n",
    "                )\n",
    "            # from section 4.1 of the paper, initializing params of BN ensures that the initial state of non-local block is identity mapping\n",
    "            nn.init.constant_(self.W_z[1].weight, 0)\n",
    "            nn.init.constant_(self.W_z[1].bias, 0)\n",
    "        else:\n",
    "            self.W_z = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1)\n",
    "\n",
    "            # from section 3.3 of the paper by initializing Wz to 0, this block can be inserted to any existing architecture\n",
    "            nn.init.constant_(self.W_z.weight, 0)\n",
    "            nn.init.constant_(self.W_z.bias, 0)\n",
    "\n",
    "        # define theta and phi for all operations except gaussian\n",
    "        if self.mode == \"embedded\" or self.mode == \"dot\" or self.mode == \"concatenate\":\n",
    "            self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "            self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "        \n",
    "        if self.mode == \"concatenate\":\n",
    "            self.W_f = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=self.inter_channels * 2, out_channels=1, kernel_size=1),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        args\n",
    "            x: (N, C, T, H, W) for dimension=3; (N, C, H, W) for dimension 2; (N, C, T) for dimension 1\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # (N, C, THW)\n",
    "        # this reshaping and permutation is from the spacetime_nonlocal function in the original Caffe2 implementation\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        if self.mode == \"gaussian\":\n",
    "            theta_x = x.view(batch_size, self.in_channels, -1)\n",
    "            phi_x = x.view(batch_size, self.in_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "        elif self.mode == \"embedded\" or self.mode == \"dot\":\n",
    "            theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "            phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "        elif self.mode == \"concatenate\":\n",
    "            theta_x = self.theta(x).view(batch_size, self.inter_channels, -1, 1)\n",
    "            phi_x = self.phi(x).view(batch_size, self.inter_channels, 1, -1)\n",
    "            \n",
    "            h = theta_x.size(2)\n",
    "            w = phi_x.size(3)\n",
    "            theta_x = theta_x.repeat(1, 1, 1, w)\n",
    "            phi_x = phi_x.repeat(1, 1, h, 1)\n",
    "            \n",
    "            concat = torch.cat([theta_x, phi_x], dim=1)\n",
    "            f = self.W_f(concat)\n",
    "            f = f.view(f.size(0), f.size(2), f.size(3))\n",
    "        \n",
    "        if self.mode == \"gaussian\" or self.mode == \"embedded\":\n",
    "            f_div_C = F.softmax(f, dim=-1)\n",
    "        elif self.mode == \"dot\" or self.mode == \"concatenate\":\n",
    "            N = f.size(-1) # number of position in x\n",
    "            f_div_C = f / N\n",
    "        \n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        \n",
    "        # contiguous here just allocates contiguous chunk of memory\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        \n",
    "        W_y = self.W_z(y)\n",
    "        # residual connection\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     import torch\n",
    "\n",
    "#     for bn_layer in [True, False]:\n",
    "#         img = torch.zeros(2, 3, 20)\n",
    "#         net = NLBlockND(in_channels=3, mode='concatenate', dimension=1, bn_layer=bn_layer)\n",
    "#         out = net(img)\n",
    "#         print(out.size())\n",
    "        \n",
    "class TwoConv(nn.Sequential):\n",
    "    \"\"\"two convolutions.\"\"\"\n",
    "\n",
    "    @deprecated_arg(name=\"dim\", new_name=\"spatial_dims\", since=\"0.6\", msg_suffix=\"Please use `spatial_dims` instead.\")\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_chns: int,\n",
    "        out_chns: int,\n",
    "        act: Union[str, tuple],\n",
    "        norm: Union[str, tuple],\n",
    "        bias: bool,\n",
    "        dropout: Union[float, tuple] = 0.0,\n",
    "        dim: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions.\n",
    "            in_chns: number of input channels.\n",
    "            out_chns: number of output channels.\n",
    "            act: activation type and arguments.\n",
    "            norm: feature normalization type and arguments.\n",
    "            bias: whether to have a bias term in convolution blocks.\n",
    "            dropout: dropout ratio. Defaults to no dropout.\n",
    "\n",
    "        .. deprecated:: 0.6.0\n",
    "            ``dim`` is deprecated, use ``spatial_dims`` instead.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if dim is not None:\n",
    "            spatial_dims = dim\n",
    "        conv_0 = Convolution(spatial_dims, in_chns, out_chns, act=act, norm=norm, dropout=dropout, bias=bias, padding=1)\n",
    "        conv_1 = Convolution(spatial_dims, out_chns, out_chns, act=act, norm=norm, dropout=dropout, bias=bias, padding=1)\n",
    "        \n",
    "        self.add_module(\"conv_0\", conv_0)\n",
    "        self.add_module(\"conv_1\", conv_1)\n",
    "\n",
    "\n",
    "class Down(nn.Sequential):\n",
    "    \"\"\"maxpooling downsampling and two convolutions.\"\"\"\n",
    "\n",
    "    @deprecated_arg(name=\"dim\", new_name=\"spatial_dims\", since=\"0.6\", msg_suffix=\"Please use `spatial_dims` instead.\")\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_chns: int,\n",
    "        out_chns: int,\n",
    "        act: Union[str, tuple],\n",
    "        norm: Union[str, tuple],\n",
    "        bias: bool,\n",
    "        dropout: Union[float, tuple] = 0.0,\n",
    "        dim: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions.\n",
    "            in_chns: number of input channels.\n",
    "            out_chns: number of output channels.\n",
    "            act: activation type and arguments.\n",
    "            norm: feature normalization type and arguments.\n",
    "            bias: whether to have a bias term in convolution blocks.\n",
    "            dropout: dropout ratio. Defaults to no dropout.\n",
    "\n",
    "        .. deprecated:: 0.6.0\n",
    "            ``dim`` is deprecated, use ``spatial_dims`` instead.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if dim is not None:\n",
    "            spatial_dims = dim\n",
    "        max_pooling = Pool[\"MAX\", spatial_dims](kernel_size=2)\n",
    "        convs = TwoConv(spatial_dims, in_chns, out_chns, act, norm, bias, dropout)\n",
    "        self.add_module(\"max_pooling\", max_pooling)\n",
    "        self.add_module(\"convs\", convs)\n",
    "\n",
    "class UpCat(nn.Module):\n",
    "    \"\"\"upsampling, concatenation with the encoder feature map, two convolutions\"\"\"\n",
    "\n",
    "    @deprecated_arg(name=\"dim\", new_name=\"spatial_dims\", since=\"0.6\", msg_suffix=\"Please use `spatial_dims` instead.\")\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int,\n",
    "        in_chns: int,\n",
    "        cat_chns: int,\n",
    "        out_chns: int,\n",
    "        act: Union[str, tuple],\n",
    "        norm: Union[str, tuple],\n",
    "        bias: bool,\n",
    "        dropout: Union[float, tuple] = 0.0,\n",
    "        upsample: str = \"deconv\",\n",
    "        pre_conv: Optional[Union[nn.Module, str]] = \"default\",\n",
    "        interp_mode: str = \"linear\",\n",
    "        align_corners: Optional[bool] = True,\n",
    "        halves: bool = True,\n",
    "        dim: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions.\n",
    "            in_chns: number of input channels to be upsampled.\n",
    "            cat_chns: number of channels from the decoder.\n",
    "            out_chns: number of output channels.\n",
    "            act: activation type and arguments.\n",
    "            norm: feature normalization type and arguments.\n",
    "            bias: whether to have a bias term in convolution blocks.\n",
    "            dropout: dropout ratio. Defaults to no dropout.\n",
    "            upsample: upsampling mode, available options are\n",
    "                ``\"deconv\"``, ``\"pixelshuffle\"``, ``\"nontrainable\"``.\n",
    "            pre_conv: a conv block applied before upsampling.\n",
    "                Only used in the \"nontrainable\" or \"pixelshuffle\" mode.\n",
    "            interp_mode: {``\"nearest\"``, ``\"linear\"``, ``\"bilinear\"``, ``\"bicubic\"``, ``\"trilinear\"``}\n",
    "                Only used in the \"nontrainable\" mode.\n",
    "            align_corners: set the align_corners parameter for upsample. Defaults to True.\n",
    "                Only used in the \"nontrainable\" mode.\n",
    "            halves: whether to halve the number of channels during upsampling.\n",
    "                This parameter does not work on ``nontrainable`` mode if ``pre_conv`` is `None`.\n",
    "\n",
    "        .. deprecated:: 0.6.0\n",
    "            ``dim`` is deprecated, use ``spatial_dims`` instead.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if dim is not None:\n",
    "            spatial_dims = dim\n",
    "        if upsample == \"nontrainable\" and pre_conv is None:\n",
    "            up_chns = in_chns\n",
    "        else:\n",
    "            up_chns = in_chns // 2 if halves else in_chns\n",
    "        self.upsample = UpSample(\n",
    "            spatial_dims,\n",
    "            in_chns,\n",
    "            up_chns,\n",
    "            2,\n",
    "            mode=upsample,\n",
    "            pre_conv=pre_conv,\n",
    "            interp_mode=interp_mode,\n",
    "            align_corners=align_corners,\n",
    "        )\n",
    "        self.convs = TwoConv(spatial_dims, cat_chns + up_chns, out_chns, act, norm, bias, dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, x_e: Optional[torch.Tensor]):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            x: features to be upsampled.\n",
    "            x_e: features from the encoder.\n",
    "        \"\"\"\n",
    "        x_0 = self.upsample(x)\n",
    "\n",
    "        if x_e is not None:\n",
    "            # handling spatial shapes due to the 2x maxpooling with odd edge lengths.\n",
    "            dimensions = len(x.shape) - 2\n",
    "            sp = [0] * (dimensions * 2)\n",
    "            for i in range(dimensions):\n",
    "                if x_e.shape[-i - 1] != x_0.shape[-i - 1]:\n",
    "                    sp[i * 2 + 1] = 1\n",
    "            x_0 = torch.nn.functional.pad(x_0, sp, \"replicate\")\n",
    "            x = self.convs(torch.cat([x_e, x_0], dim=1))  # input channels: (cat_chns + up_chns)\n",
    "        else:\n",
    "            x = self.convs(x_0)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class monai_unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        spatial_dims: int = 2,\n",
    "        net_inputch: int = 1,\n",
    "        net_outputch: int = 2,\n",
    "        net_bayesian = 0,\n",
    "        # features: Sequence[int] = (32, 32, 64, 128, 256, 32),\n",
    "        features: Sequence[int] = (32, 32, 64, 128, 256, 512, 32),\n",
    "        act: Union[str, tuple] = (\"LeakyReLU\", {\"negative_slope\": 0.1, \"inplace\": True}),\n",
    "        norm: Union[str, tuple] = (\"group\", {\"num_groups\": 8}),\n",
    "        bias: bool = True,\n",
    "        dropout: Union[float, tuple] = 0.0,\n",
    "        upsample: str = \"deconv\",\n",
    "        dimensions: Optional[int] = None,\n",
    "        bottleneck_channels = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A UNet implementation with 1D/2D/3D supports.\n",
    "\n",
    "        Based on:\n",
    "\n",
    "            Falk et al. \"U-Net – Deep Learning for Cell Counting, Detection, and\n",
    "            Morphometry\". Nature Methods 16, 67–70 (2019), DOI:\n",
    "            http://dx.doi.org/10.1038/s41592-018-0261-2\n",
    "\n",
    "        Args:\n",
    "            spatial_dims: number of spatial dimensions. Defaults to 3 for spatial 3D inputs.\n",
    "            in_channels: number of input channels. Defaults to 1.\n",
    "            out_channels: number of output channels. Defaults to 2.\n",
    "            features: six integers as numbers of features.\n",
    "                Defaults to ``(32, 32, 64, 128, 256, 32)``,\n",
    "\n",
    "                - the first five values correspond to the five-level encoder feature sizes.\n",
    "                - the last value corresponds to the feature size after the last upsampling.\n",
    "\n",
    "            act: activation type and arguments. Defaults to LeakyReLU.\n",
    "            norm: feature normalization type and arguments. Defaults to instance norm.\n",
    "            bias: whether to have a bias term in convolution blocks. Defaults to True.\n",
    "                According to `Performance Tuning Guide <https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html>`_,\n",
    "                if a conv layer is directly followed by a batch norm layer, bias should be False.\n",
    "            dropout: dropout ratio. Defaults to no dropout.\n",
    "            upsample: upsampling mode, available options are\n",
    "                ``\"deconv\"``, ``\"pixelshuffle\"``, ``\"nontrainable\"``.\n",
    "\n",
    "        .. deprecated:: 0.6.0\n",
    "            ``dimensions`` is deprecated, use ``spatial_dims`` instead.\n",
    "\n",
    "        Examples::\n",
    "\n",
    "            # for spatial 2D\n",
    "            >>> net = BasicUNet(spatial_dims=2, features=(64, 128, 256, 512, 1024, 128))\n",
    "\n",
    "            # for spatial 2D, with group norm\n",
    "            >>> net = BasicUNet(spatial_dims=2, features=(64, 128, 256, 512, 1024, 128), norm=(\"group\", {\"num_groups\": 4}))\n",
    "\n",
    "            # for spatial 3D\n",
    "            >>> net = BasicUNet(spatial_dims=3, features=(32, 32, 64, 128, 256, 32))\n",
    "\n",
    "        See Also\n",
    "\n",
    "            - :py:class:`monai.networks.nets.DynUNet`\n",
    "            - :py:class:`monai.networks.nets.UNet`\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if dimensions is not None:\n",
    "            spatial_dims = dimensions\n",
    "\n",
    "        fea = ensure_tuple_rep(features, 7)\n",
    "        print(f\"BasicUNet features: {fea}.\")\n",
    "        in_channels = net_inputch\n",
    "        out_channels = net_outputch\n",
    "        \n",
    "        self.NLBlock_1 = NLBlockND(in_channels=fea[1], mode='dot', dimension=2)\n",
    "        self.NLBlock_2 = NLBlockND(in_channels=fea[2], mode='dot', dimension=2)\n",
    "        self.NLBlock_3 = NLBlockND(in_channels=fea[3], mode='dot', dimension=2)\n",
    "        self.NLBlock_4 = NLBlockND(in_channels=fea[4], mode='dot', dimension=2)\n",
    "        self.NLBlock_5 = NLBlockND(in_channels=fea[5], mode='dot', dimension=2)\n",
    "        \n",
    "        self.skipAtt = attention_block(F_g=fea[4],F_l=fea[4],F_int=fea[4])\n",
    "        self.conv_0 = TwoConv(spatial_dims, in_channels, features[0], act, norm, bias, dropout)\n",
    "        self.down_1 = Down(spatial_dims, fea[0], fea[1], act, norm, bias, dropout)\n",
    "        self.down_2 = Down(spatial_dims, fea[1], fea[2], act, norm, bias, dropout)\n",
    "        self.down_3 = Down(spatial_dims, fea[2], fea[3], act, norm, bias, dropout)\n",
    "        self.down_4 = Down(spatial_dims, fea[3], fea[4], act, norm, bias, dropout)\n",
    "        self.down_5 = Down(spatial_dims, fea[4], fea[5], act, norm, bias, dropout)\n",
    "\n",
    "        self.upcat_5 = UpCat(spatial_dims, fea[5], fea[4], fea[4], act, norm, bias, dropout, upsample)\n",
    "        self.upcat_4 = UpCat(spatial_dims, fea[4], fea[3], fea[3], act, norm, bias, dropout, upsample)\n",
    "        self.upcat_3 = UpCat(spatial_dims, fea[3], fea[2], fea[2], act, norm, bias, dropout, upsample)\n",
    "        self.upcat_2 = UpCat(spatial_dims, fea[2], fea[1], fea[1], act, norm, bias, dropout, upsample)\n",
    "        # self.upcat_1 = UpCat(spatial_dims, fea[1], fea[0], fea[5], act, norm, bias, dropout, upsample, halves=False)\n",
    "        self.upcat_1 = UpCat(spatial_dims, fea[1], fea[0], fea[6], act, norm, bias, dropout, upsample, halves=False)\n",
    "\n",
    "        # self.final_conv = Conv[\"conv\", spatial_dims](fea[5], out_channels, kernel_size=1)\n",
    "        self.final_conv = Conv[\"conv\", spatial_dims](fea[6], out_channels, kernel_size=1)\n",
    "        self.bottleneck_channels = bottleneck_channels \n",
    "        \n",
    "        if self.bottleneck_channels is not None:\n",
    "            pool = nn.AdaptiveAvgPool1d(1)\n",
    "            flatten = nn.Flatten()\n",
    "            dropout = nn.Dropout(p=.2, inplace=True) if dropout else nn.Identity()\n",
    "            linear = nn.Linear(fea[5], regression_channels, bias=True)\n",
    "            activation = nn.Sigmoid() # nn.ReLU()\n",
    "            self.bottleneck_head = nn.Sequential(pool,flatten,dropout,linear,activation)\n",
    "    \n",
    "        if net_bayesian!=0:\n",
    "            self.MCDropout = MCDropout(p=net_bayesian)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: input should have spatially N dimensions\n",
    "                ``(Batch, in_channels, dim_0[, dim_1, ..., dim_N])``, N is defined by `dimensions`.\n",
    "                It is recommended to have ``dim_n % 16 == 0`` to ensure all maxpooling inputs have\n",
    "                even edge lengths.\n",
    "\n",
    "        Returns:\n",
    "            A torch Tensor of \"raw\" predictions in shape\n",
    "            ``(Batch, out_channels, dim_0[, dim_1, ..., dim_N])``.\n",
    "        \"\"\"\n",
    "        x0 = self.conv_0(x)\n",
    "\n",
    "        x1 = self.down_1(x0)\n",
    "        # x1 = self.NLBlock_1(x1)\n",
    "        \n",
    "        x2 = self.down_2(x1)\n",
    "        x2 = self.NLBlock_2(x2)\n",
    "        \n",
    "        x2 = self.MCDropout(x2)\n",
    "        x3 = self.down_3(x2)\n",
    "        x3 = self.NLBlock_3(x3)\n",
    "        \n",
    "        x3 = self.MCDropout(x3)\n",
    "        x4 = self.down_4(x3)\n",
    "        x4 = self.NLBlock_4(x4)\n",
    "        \n",
    "        x4 = self.MCDropout(x4)\n",
    "        x5 = self.down_5(x4)\n",
    "        x5 = self.NLBlock_5(x5)\n",
    "        \n",
    "        u5 = self.upcat_5(x5, x4)\n",
    "        u4 = self.upcat_4(u5, x3)\n",
    "        u4 = self.NLBlock_3(u4)\n",
    "        \n",
    "        u3 = self.upcat_3(u4, x2)\n",
    "        u3 = self.NLBlock_2(u3)\n",
    "        \n",
    "        u2 = self.upcat_2(u3, x1)\n",
    "        u1 = self.upcat_1(u2, x0)\n",
    "\n",
    "        x = self.final_conv(u1)\n",
    "        # x = F.sigmoid(x)\n",
    "        \n",
    "        if self.bottleneck_channels is None:\n",
    "            return x\n",
    "        else:\n",
    "            y = self.bottleneck_head(x4)            \n",
    "            return x, y\n",
    "        \n",
    "\n",
    "\n",
    "class attention_block(nn.Module):\n",
    "    def __init__(self,F_g,F_l,F_int):\n",
    "        super(attention_block,self).__init__()\n",
    "#         inplace= True\n",
    "        inplace= False\n",
    "\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "            )\n",
    "\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=inplace)\n",
    "        \n",
    "    def forward(self,g,x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1+x1)\n",
    "        psi = self.psi(psi)\n",
    "\n",
    "        return x*psi  \n",
    "    \n",
    "\n",
    "class MCDropout(nn.Dropout):\n",
    "    def forward(self, input):\n",
    "        return F.dropout(input, self.p, True, self.inplace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "542db311-ce2b-475e-bb42-5b2f42e76cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (32, 32, 64, 128, 256, 512, 32).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "monai_unet(\n",
       "  (NLBlock_1): NLBlockND(\n",
       "    (g): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (W_z): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (theta): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (phi): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (NLBlock_2): NLBlockND(\n",
       "    (g): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (W_z): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (theta): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (phi): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (NLBlock_3): NLBlockND(\n",
       "    (g): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (W_z): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (theta): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (phi): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (NLBlock_4): NLBlockND(\n",
       "    (g): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (W_z): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (theta): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (phi): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (NLBlock_5): NLBlockND(\n",
       "    (g): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (W_z): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (theta): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (phi): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (skipAtt): attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv_0): TwoConv(\n",
       "    (conv_0): Convolution(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (adn): ADN(\n",
       "        (N): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (D): Dropout(p=0.0, inplace=False)\n",
       "        (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv_1): Convolution(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (adn): ADN(\n",
       "        (N): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (D): Dropout(p=0.0, inplace=False)\n",
       "        (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_1): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_2): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_3): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_4): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down_5): Down(\n",
       "    (max_pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_5): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_4): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_3): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_2): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (upcat_1): UpCat(\n",
       "    (upsample): UpSample(\n",
       "      (deconv): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (convs): TwoConv(\n",
       "      (conv_0): Convolution(\n",
       "        (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (conv_1): Convolution(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (adn): ADN(\n",
       "          (N): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "          (D): Dropout(p=0.0, inplace=False)\n",
       "          (A): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (MCDropout): MCDropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = monai_unet(spatial_dims= 2,\n",
    "                net_inputch = 3,\n",
    "                net_outputch = 2,net_bayesian=0.2,\n",
    "                norm=(\"group\", {\"num_groups\": 8})\n",
    "               )\n",
    "\n",
    "a = torch.rand(2,3,320,320)\n",
    "b = net(a)\n",
    "# net = monai.networks.nets.UNet(spatial_dims= 3,\n",
    "#                 in_channels = 3,\n",
    "#                 out_channels = 2,channels= \n",
    "#                 norm=(\"group\", {\"num_groups\": 8})\n",
    "#                )\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb8eacf5-a9c0-4d69-b09f-f362d11e71a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected 5-dimensional input for 5-dimensional weight [32, 3, 3, 3, 3], but got 4-dimensional input of size [2, 3, 320, 320] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25553/2005934916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# net = monai.networks.nets.UNETR(spatial_dims=2, in_channels=3, out_channels=2, img_size=320, feature_size=32, norm_name='batch')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_25553/706127226.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_N\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \"\"\"\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    518\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_triple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                             self.dilation, self.groups)\n\u001b[0;32m--> 520\u001b[0;31m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    521\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 5-dimensional input for 5-dimensional weight [32, 3, 3, 3, 3], but got 4-dimensional input of size [2, 3, 320, 320] instead"
     ]
    }
   ],
   "source": [
    "net = monai.networks.nets.UNETR(spatial_dims=2, in_channels=3, out_channels=2, img_size=320, feature_size=32, norm_name='batch')\n",
    "a = torch.rand(2,3,320,320)\n",
    "b = net(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03efe82-6c0c-40db-a190-b542ee17463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797837f-d2dd-4a90-9deb-c7c8a902d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = monai.networks.nets.UNETR(\n",
    "        in_channels=3,\n",
    "        out_channels=2,\n",
    "        img_size=(320, 320),\n",
    "        feature_size=16,\n",
    "        hidden_size=768,\n",
    "        mlp_dim=3072,\n",
    "        num_heads=12,\n",
    "        pos_embed=\"conv\",\n",
    "        norm_name=\"instance\",\n",
    "        res_block=True,\n",
    "        dropout_rate=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd0036c-3dc0-4a3b-be49-b6b800559575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataset = datasets.dataset_CLAHE('DRIVE2CH','train',transform=datasets.augmentation_train(),adaptive_hist_range=False)\n",
    "train_loader = DataLoader(train_dataset)\n",
    "\n",
    "test_dataset = datasets.dataset_CLAHE('DRIVE2CH','test',adaptive_hist_range=False)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "\n",
    "# test_dataset = datasets.dataset('Fundusphotography','test', adaptive_hist_range=False)\n",
    "# test_loader = DataLoader(test_dataset)\n",
    "\n",
    "# test_dataset = datasets.dataset('../Retina/dataset/HRF','test',adaptive_hist_range=False)\n",
    "# test_loader = DataLoader(test_dataset)\n",
    "\n",
    "for idx,batch in enumerate(train_loader):\n",
    "    x,y = batch['x'], batch['y']\n",
    "    plt.imshow(x.permute(0,2,3,1)[0])\n",
    "    # plt.imshow(y[0,0],alpha=0.5,cmap='gray')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31cc78-dfb7-462f-b560-e28157c0a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fil_finder import FilFinder2D\n",
    "import astropy.units as u\n",
    "import skimage\n",
    "import skimage.morphology\n",
    "from skimage.morphology import skeletonize, medial_axis, dilation, disk, remove_small_objects\n",
    "\n",
    "def postprocess(mask):\n",
    "    mask = mask.astype(np.bool)\n",
    "    return skimage.morphology.remove_small_objects(mask,400)*1\n",
    "\n",
    "\n",
    "def skeletion_analysis(image,skeleton):\n",
    "    # fil = FilFinder2D(distance, mask = skeleton)\n",
    "    fil = FilFinder2D(image, mask = skeleton)\n",
    "    # filfind.preprocess_image(flatten_percent=85)\n",
    "    fil.create_mask(border_masking = True, verbose = False, use_existing_mask = True)\n",
    "    fil.medskel(verbose = False)\n",
    "    fil.analyze_skeletons(branch_thresh = 10 * u.pix, skel_thresh = 10 * u.pix, prune_criteria = 'all')\n",
    "    # fil.analyze_skeletons(branch_thresh = 10 * u.pix, skel_thresh = 10 * u.pix, prune_criteria = 'all', verbose=True)\n",
    "\n",
    "    # Show the longest path\n",
    "    plt.figure(figsize=(18,8))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(image, cmap = 'gray')\n",
    "    # plt.imshow(distance, cmap = 'gray')\n",
    "    plt.imshow(fil.skeleton, cmap = 'gray',alpha=0.5)\n",
    "    plt.contour(fil.skeleton, colors = 'r', alpha=0.3)\n",
    "    plt.axis('off')\n",
    "\n",
    "    print(len(fil.filaments))\n",
    "    fil1 = fil.filaments[0]\n",
    "    plt.subplot(122)\n",
    "    plt.plot(fil1.ridge_profile(fil.image))\n",
    "    plt.xlabel('Length(Pixel)')\n",
    "    plt.ylabel('Thickness(Pixel)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # fil1.skeleton_analysis(fil.image, verbose=True)\n",
    "    print(fil.branch_properties.keys())\n",
    "    # fil.find_widths(verbose=True, max_dist=200 *u.pix, pad_to_distance= 0 *u.pix, use_longest_path=True, xunit=u.pix)\n",
    "    \n",
    "skeleton,distance = medial_axis(y.numpy()[0,0], return_distance=True)\n",
    "image = x.numpy()[0,0]\n",
    "# skeletion_analysis(image,skeleton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea986ae9-d5a9-47da-bec0-c28c413d1948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fil = FilFinder2D(distance, mask = skeleton)\n",
    "fil = FilFinder2D(image, mask = skeleton)\n",
    "# filfind.preprocess_image(flatten_percent=85)\n",
    "fil.create_mask(border_masking = True, verbose = False, use_existing_mask = True)\n",
    "fil.medskel(verbose = False)\n",
    "fil.analyze_skeletons(branch_thresh = 10 * u.pix, skel_thresh = 10 * u.pix, prune_criteria = 'all')\n",
    "# fil.analyze_skeletons(branch_thresh = 10 * u.pix, skel_thresh = 10 * u.pix, prune_criteria = 'all', verbose=True)\n",
    "\n",
    "# Show the longest path\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(image, cmap = 'gray')\n",
    "# plt.imshow(distance, cmap = 'gray')\n",
    "plt.imshow(fil.skeleton, cmap = 'gray',alpha=0.5)\n",
    "plt.contour(fil.skeleton, colors = 'r', alpha=0.3)\n",
    "plt.axis('off')\n",
    "\n",
    "print(len(fil.filaments))\n",
    "fil1 = fil.filaments[0]\n",
    "plt.subplot(122)\n",
    "plt.plot(fil1.ridge_profile(fil.image))\n",
    "plt.xlabel('Length(Pixel)')\n",
    "plt.ylabel('Thickness(Pixel)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# fil1.skeleton_analysis(fil.image, verbose=True)\n",
    "print(fil.branch_properties.keys())\n",
    "# fil.find_widths(verbose=True, max_dist=200 *u.pix, pad_to_distance= 0 *u.pix, use_longest_path=True, xunit=u.pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669ace3-cb8c-4bd7-b8c8-4b26ee4192d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# branchpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b733c-4ddf-4b17-b472-fb8d56f3788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(fil1.branch_pts())\n",
    "branchpt = fil1.branch_pts()\n",
    "array_branchpt = np.zeros_like(label)\n",
    "for idx in range(len(branchpt)):\n",
    "    for idx_ in range(len(branchpt[idx])):\n",
    "        x,y = branchpt[idx][idx_]\n",
    "        array_branchpt[x,y] = 1\n",
    "plt.imshow(array_branchpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3e1f0-c32c-4385-ad1e-8675c06c7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil1.plot_graph()\n",
    "# fil1.skeleton_analysis(fil.image, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22874fec-eeac-454d-b114-dced7b4355a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil.branch_properties['number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8aa7e-e8db-4034-843c-f54d5f120bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a272a277-70be-4086-9f90-cae261726d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance[distance==0]=1000\n",
    "label = np.exp(-distance/16)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954ea29-fb5d-4562-9086-a26ae06e487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86167298-bb1f-4b54-9d76-f86c830a28bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(1/distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40245e59-18a4-49e4-bdfe-57b3682af4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "plt.imshow(y[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942eef74-f271-4ec6-9e3d-60c0ad2d5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.subplot(121)\n",
    "# plt.imshow(distance)\n",
    "plt.imshow(y[0][0])\n",
    "distance[distance==0]=1000\n",
    "plt.subplot(122)\n",
    "plt.imshow(1/distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb38e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu status\n",
    "!nvidia-smi\n",
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "# !pip install tensorboard==1.15\n",
    "gpus= \"0\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus;\n",
    "    \n",
    "import torch\n",
    "gpu_count = torch.cuda.device_count()\n",
    "if gpu_count >=1:\n",
    "    torch.multiprocessing.set_start_method('spawn')\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(gpu_count)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220dd9a8-cfe0-40ff-b110-9232c4ef3e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nets\n",
    "net= nets.unet(net_bayesian=0.2)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d26e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nets\n",
    "import torch\n",
    "net= nets.smp_unet(net_bayesian=True)\n",
    "a= torch.rand(2,3,128,128)\n",
    "b= net(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15121ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "net = smp.Unet(encoder_name='resnet50',encoder_weights=None)\n",
    "# net = smp.Unet(encoder_name='densenet169',encoder_weights=None)\n",
    "# net = smp.Unet(encoder_name='timm-efficientnet-b5',encoder_weights=None)\n",
    "# net = smp.Unet(encoder_name='timm-regnety_040',encoder_weights=None)\n",
    "# net = smp.Unet(encoder_name='timm-skresnext50_32x4d',encoder_weights='imagenet')\n",
    "# net = smp.DeepLabV3Plus(encoder_name='resnet50',encoder_weights=None)\n",
    "\n",
    "net.encoder\n",
    "# net.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369e0a4-772f-4ed7-8018-a4498d038cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.encoder.layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(net.encoder.children())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23028d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(net.encoder.children())[-1][-1].b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55673e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.encoder.s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import nets\n",
    "MCDropout = nets.MCDropout()\n",
    "\n",
    "net.encoder.layer4 = nn.Sequential(MCDropout, net.encoder.layer4)\n",
    "net.encoder.layer4\n",
    "# net.encoder.s4 = nn.Sequential(MCDropout,net.encoder.s4) # regnet\n",
    "# net.encoder.s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import nets\n",
    "MCDropout = nets.MCDropout()\n",
    "\n",
    "list(net.encoder.children())[-1][-1] = nn.Sequential(MCDropout,list(net.encoder.children())[-1][-1]) # resnet, densenet\n",
    "list(net.encoder.children())[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.encoder.bn2 =  nn.Sequential(net.encoder.bn2 ,MCDropout) # efficientnet\n",
    "net.encoder.bn2 =  nn.Sequential(net.encoder.bn2 ,MCDropout) # efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e650de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import nets\n",
    "MCDropout = nets.MCDropout()\n",
    "\n",
    "list(net.encoder.children())[-1] = nn.Sequential(MCDropout,list(net.encoder.children())[-1]) # \n",
    "list(net.encoder.children())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca4331",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = list(net.encoder.children())\n",
    "# layer_last = 0\n",
    "\n",
    "# while layer_last==0:\n",
    "#     try:\n",
    "#         layers = layers[-1]\n",
    "#     except:\n",
    "#         layer_last = layers\n",
    "        \n",
    "# print('before',layer_last)\n",
    "# layer_last = nn.Sequential(layer_last, MCDropout)\n",
    "# print('after',layer_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deb0874",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= net(a)\n",
    "# b= net.encoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9fcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197dd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.encoder = nn.Sequential(*list(net.encoder.modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647ec78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1,3,128,128)\n",
    "b = net.encoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b3bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c52d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993d8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a488b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= net.encoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b569de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "import torch\n",
    "import glob\n",
    "import nets\n",
    "import monai\n",
    "\n",
    "# # !CUDA_VISIBLE_DEVICES=2 python train.py --project Retina \\\n",
    "# #                                         --data_dir DRIVE2CH \\\n",
    "# #                                         --data_module dataset \\\n",
    "# #                                         --net_name smp_unet \\\n",
    "# #                                         --net_inputch 3 \\\n",
    "# #                                         --net_outputch 2 \\\n",
    "# #                                         --net_encoder_name resnet152 \\\n",
    "# #                                         --net_norm batch \\\n",
    "# #                                         --net_baysian True \\\n",
    "# #                                         --lossfn skel_FocalLoss \\\n",
    "# #                                         --data_padsize None \\\n",
    "# #                                         --data_cropsize None \\\n",
    "# #                                         --data_resize 584_565 \\\n",
    "# #                                         --data_patchsize 224_224 \\\n",
    "# #                                         --batch_size 12 \\\n",
    "# #                                         --lr 1e-3 \\\n",
    "# #                                         --precision 32 \\\n",
    "\n",
    "net = train.SegModel(data_dir='DRIVE2CH',project='Retina',\n",
    "                     net_name='smp_unet',\n",
    "                     net_inputch=3,\n",
    "                     net_outputch=2,\n",
    "                     net_encoder_name='resnet50',\n",
    "                     net_norm = 'batch',\n",
    "                     net_baysian=True,\n",
    "                     lossfn='BoundaryFocalLoss',\n",
    "                     data_padsize = None,\n",
    "                     data_cropsize = None,\n",
    "                     data_resize = 584_565,\n",
    "                     data_patchsize = '320_320',\n",
    "                    ).cuda()\n",
    "\n",
    "PATH = 'logs/Retina/2zs1jtfs/checkpoints/' # AMC\n",
    "PATH = 'logs/Retina/f1trgt7t/checkpoints/' # DRIVE\n",
    "# PATH = 'logs/Retina/i7s4t3w2/checkpoints/' # DRIVE\n",
    "# keewonshin/Retina/f1trgt7t\n",
    "FILE = glob.glob(PATH+'*.ckpt')\n",
    "print(FILE,'\\n',FILE[-1])\n",
    "weight = torch.load(FILE[-1])\n",
    "\n",
    "net.load_state_dict(weight['state_dict'],strict=False)\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a106afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train\n",
    "# import torch\n",
    "# import glob\n",
    "# import nets\n",
    "\n",
    "# net = train.SegModel(data_dir='DRIVE_2c',project='Retina',\n",
    "#                      net='smp_FPNRecSoft',\n",
    "#                      net_inputch=3,\n",
    "#                      net_outputch=2,\n",
    "#                      net_finalActivation=True,\n",
    "#                      net_nnblock=True,\n",
    "#                      net_supervision=True,\n",
    "#                      net_skipatt=True,\n",
    "#                      net_wavelet=True,\n",
    "#                      net_rcnn=False,\n",
    "#                      net_reconstruction=True,\n",
    "#                      data_padsize =None,\n",
    "#                      data_cropsize =None,\n",
    "#                      data_resize =None,\n",
    "#                      data_patchsize = '256_256',\n",
    "#                     ).cuda()\n",
    "\n",
    "# PATH = 'logs/Retina/13hcx6pe/checkpoints/'\n",
    "\n",
    "# FILE = glob.glob(PATH+'*.ckpt')\n",
    "# print(FILE,'\\n',FILE[-1])\n",
    "# weight = torch.load(FILE[-1])\n",
    "\n",
    "# net.load_state_dict(weight['state_dict'],strict=False)\n",
    "# # net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train\n",
    "# import torch\n",
    "# import glob\n",
    "# import nets\n",
    "\n",
    "# net = train.SegModel(data_dir='DRIVE_2c',project='Retina',\n",
    "#                      net='smp_FPNRecHard',\n",
    "#                      net_inputch=3,\n",
    "#                      net_outputch=2,\n",
    "#                      net_finalActivation=True,\n",
    "#                      net_nnblock=True,\n",
    "#                      net_supervision=True,\n",
    "#                      net_skipatt=True,\n",
    "#                      net_wavelet=True,\n",
    "#                      net_rcnn=False,\n",
    "#                      net_reconstruction=True,\n",
    "#                      data_padsize =None,\n",
    "#                      data_cropsize =None,\n",
    "#                      data_resize =None,\n",
    "#                      data_patchsize = '256_256',\n",
    "#                     ).cuda()\n",
    "\n",
    "# PATH = 'logs/Retina/1muq8j90/checkpoints/'\n",
    "\n",
    "# FILE = glob.glob(PATH+'*.ckpt')\n",
    "# # print(FILE,'\\n',FILE[-1])\n",
    "# weight = torch.load(FILE[-1])\n",
    "\n",
    "# net.load_state_dict(weight['state_dict'],strict=False)\n",
    "# # net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch_lightning as pl\n",
    "# import train\n",
    "# import torch\n",
    "# import glob\n",
    "# import nets\n",
    "\n",
    "# model = MyLightingModule.load_from_checkpoint(PATH)\n",
    "\n",
    "# print(model.learning_rate)\n",
    "# # prints the learning_rate you used in this checkpoint\n",
    "\n",
    "# model.eval()\n",
    "# y_hat = model(x)\n",
    "\n",
    "# trainer = pl.Trainer(gpus = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c8a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# files = glob.glob('DRIVE2CH_CHASE_HRF/*.jpg')\n",
    "# for idx in range(len(files)):\n",
    "#     img = cv2.imread(files[idx])\n",
    "#     img[img!=0] = 0\n",
    "#     img[img==0] = 23\n",
    "#     cv2.imwrite(files[idx],img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47887ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# img = cv2.imread(files[idx])\n",
    "# np.unique(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# # img = cv2.imread(files[idx])\n",
    "\n",
    "# img = np.load(files[idx])\n",
    "# artery = img[...,0] + img[...,2]\n",
    "# vein = img[...,1] + img [...,2]\n",
    "# artery[artery!=0] = 1\n",
    "# vein[vein!=0] = 1\n",
    "\n",
    "# plt.imshow(artery*255)\n",
    "# plt.show()\n",
    "# plt.imshow(vein*255)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1496bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataset = datasets.dataset_CLAHE('DRIVE2CH','train',transform=datasets.augmentation_train(),adaptive_hist_range=False)\n",
    "train_loader = DataLoader(train_dataset)\n",
    "\n",
    "test_dataset = datasets.dataset_CLAHE('DRIVE2CH','test',adaptive_hist_range=False)\n",
    "test_loader = DataLoader(test_dataset)\n",
    "\n",
    "# test_dataset = datasets.dataset('Fundusphotography','test', adaptive_hist_range=False)\n",
    "# test_loader = DataLoader(test_dataset)\n",
    "\n",
    "# test_dataset = datasets.dataset('../Retina/dataset/HRF','test',adaptive_hist_range=False)\n",
    "# test_loader = DataLoader(test_dataset)\n",
    "\n",
    "for idx,batch in enumerate(train_loader):\n",
    "    x,y = batch['x'], batch['y']\n",
    "    plt.imshow(x.permute(0,2,3,1)[0])\n",
    "    # plt.imshow(y[0,0],alpha=0.5,cmap='gray')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,batch in enumerate(train_loader):\n",
    "    x,y = batch['x'], batch['y']\n",
    "    plt.imshow(x.permute(0,2,3,1)[0])\n",
    "    # plt.imshow(y[0,0],alpha=0.5,cmap='gray')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4e6fba-ecd9-4e30-ab31-fe6dd9eb151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c7a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx,batch in enumerate(train_loader):\n",
    "#     x,y = batch['x'], batch['y']\n",
    "#     plt.imshow(x.permute(0,2,3,1)[0])\n",
    "# #     plt.imshow(y[0,0],alpha=0.5,cmap='gray')\n",
    "#     plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "def metric(yhat,y):\n",
    "    \"\"\"\n",
    "    long type inputs torch or numpy\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        yhat_ = yhat.cpu().detach().numpy().flatten()\n",
    "        y_ = y.cpu().detach().numpy().flatten()\n",
    "    except:\n",
    "        yhat_ = yhat.flatten()\n",
    "        y_ = y.flatten()\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_, yhat_).ravel()\n",
    "    accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "    iou = tp/(tp+fp+fn)\n",
    "    dice = 2*tp/(2*tp+fp+fn)\n",
    "    specificity = tn / (tn+fp)\n",
    "    sensitivity = tp / (tp+fn)\n",
    "    \n",
    "    return {'specificity':specificity, 'sensitivity':sensitivity, 'dice':dice, 'iou':iou, 'accuracy':accuracy}\n",
    "\n",
    "def show_image_samples(x, y, yhat, message=''):\n",
    "    '''\n",
    "    all inputs should be shaped in BxCxHxW. (only for 2D segmentation)\n",
    "    If prediction shape channel more than 2, you need to argmax it. (fixed)\n",
    "    The first element of the batch will shown.\n",
    "    '''\n",
    "    \n",
    "    plt.figure(figsize=(24,16))\n",
    "    plt.subplot(131)\n",
    "    plt.title(str(message)+'_x')\n",
    "    plt.imshow(x,cmap='gray')\n",
    "    plt.subplot(132)\n",
    "    plt.title(str(message)+'_y')\n",
    "    plt.imshow(y,cmap='gray')\n",
    "    plt.subplot(133)\n",
    "    plt.title(str(message)+'_yhat')\n",
    "    plt.title(str(message)+'_y-yhat (Green:FP, Red:FN, White:TP)')\n",
    "        \n",
    "    temp = np.zeros((x.shape[0],x.shape[1],3))\n",
    "    for idx_ in range(3):\n",
    "        temp[...,idx_] = y # White (gt)\n",
    "    \n",
    "    diff = y-yhat\n",
    "    \n",
    "    diff_fp = diff.copy()\n",
    "    diff_fp[diff_fp!=-1] = 0\n",
    "    diff_fp[diff_fp!=0] = 1\n",
    "    \n",
    "    diff_fn = diff.copy()\n",
    "    diff_fn[diff_fn!=1] = 0\n",
    "    diff_fn[diff_fn!=0] = 1\n",
    "    \n",
    "    temp[...,1] -= diff_fn #R   gt-fn\n",
    "    temp[...,2] -= diff_fn #R   gt-fn\n",
    "    temp[...,1] += diff_fp #G   gt+fp\n",
    "    temp[temp!=0]=1\n",
    "    \n",
    "    plt.imshow(temp,alpha=1,cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "def show_batch_samples(batch_x, batch_y, batch_yhat, message='', x_ch = 0):\n",
    "    '''\n",
    "    all inputs should be shaped in BxCxHxW. (only for 2D segmentation)\n",
    "    If prediction shape channel more than 2, you need to argmax it. (fixed)\n",
    "    The first element of the batch will shown.\n",
    "    '''\n",
    "    \n",
    "    if len(batch_yhat.shape)==4 and batch_yhat.shape[1]>1:\n",
    "        batch_yhat = torch.argmax(batch_yhat,1).unsqueeze(1)\n",
    "    if len(batch_yhat.shape)==3:\n",
    "        batch_yhat = batch_yhat.unsqueeze(1)\n",
    "\n",
    "    idx= 0 \n",
    "    plt.figure(figsize=(24,16))\n",
    "    plt.subplot(131)\n",
    "    plt.title(str(message)+'_x')\n",
    "    plt.imshow(batch_x[idx,x_ch].cpu().detach(),cmap='gray')\n",
    "    plt.subplot(132)\n",
    "    plt.title(str(message)+'_y')\n",
    "    plt.imshow(batch_y[idx,0].cpu().detach(),cmap='gray')\n",
    "    plt.subplot(133)\n",
    "    plt.title(str(message)+'_yhat')\n",
    "    plt.title(str(message)+'_y-yhat (Green:FP, Red:FN, White:TP)')\n",
    "    \n",
    "    temp = np.zeros((batch_x[idx,0].shape[0],batch_x[idx,0].shape[1],3))\n",
    "    for idx_ in range(3):\n",
    "        temp[...,idx_] = batch_y[idx,0].cpu().detach() # White (gt)\n",
    "    diff = batch_y[idx,0].float().cpu().detach().numpy()-batch_yhat[idx,0].float().cpu().detach().numpy()\n",
    "    \n",
    "    diff_fp = diff.copy()\n",
    "    diff_fp[diff_fp!=-1] = 0\n",
    "    diff_fp[diff_fp!=0] = 1\n",
    "    diff_fn = diff.copy()\n",
    "    diff_fn[diff_fn!=1] = 0\n",
    "    diff_fn[diff_fn!=0] = 1\n",
    "    \n",
    "    temp[...,1] -= diff_fn #R   gt-fn\n",
    "    temp[...,2] -= diff_fn #R   gt-fn\n",
    "    temp[...,1] += diff_fp #G   gt+fp\n",
    "    temp[temp!=0]=1\n",
    "    \n",
    "    plt.imshow(temp,alpha=1,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b2bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.max(uncert),torch.mean(uncert),torch.std(uncert)\n",
    "# plt.imshow(1-yhat[0][0][0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb736e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import kornia\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pylab as plt\n",
    "\n",
    "def bayesian_inference_seg(net, x, iteration=50):\n",
    "    yhat_stack = []\n",
    "    net.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in range(iteration):\n",
    "#             yhat = net(x)        \n",
    "            def predictor(x, return_idx=0): # in case of prediction is type of list\n",
    "                result = net(x)\n",
    "                if isinstance(result, list) or isinstance(result, tuple):\n",
    "                    return result[return_idx]\n",
    "                else:\n",
    "                    return result\n",
    "                \n",
    "            roi_size= 320\n",
    "            yhat = sliding_window_inference(inputs=x, roi_size=roi_size, sw_batch_size=4, predictor=predictor, overlap=0.75, mode='constant')\n",
    "            yhat = utils.Activation(yhat)\n",
    "            yhat_stack.append(yhat)\n",
    "\n",
    "    yhat_stack = torch.stack(yhat_stack)\n",
    "    pred = torch.mean(yhat_stack,0)\n",
    "    pred = torch.argmax(pred,1).unsqueeze(1)\n",
    "        \n",
    "    uncert = torch.var(yhat_stack,0)\n",
    "    uncert = torch.mean(uncert,1)\n",
    "\n",
    "#     plt.imshow(pred[0,0].cpu().detach().numpy())\n",
    "#     plt.show()\n",
    "#     plt.imshow(uncert[0].cpu().detach().numpy())\n",
    "#     plt.show()\n",
    "#     plt.hist(uncert[0,0].cpu().detach().numpy())\n",
    "#     plt.show()\n",
    "    \n",
    "#     print(torch.unique(uncert))\n",
    "#     plt.imshow(pred[0,0].cpu().detach().numpy())\n",
    "#     return pred,uncert\n",
    "#     uncert[uncert<torch.std(uncert)] = 0\n",
    "#     uncert[uncert<torch.mean(uncert)] = 0\n",
    "#     print(torch.max(uncert),torch.mean(uncert),torch.std(uncert),torch.unique(uncert))\n",
    "    \n",
    "#     uncert[uncert!=0] = 1\n",
    "#     pred = pred+uncert\n",
    "#     pred[pred!=0] = 1\n",
    "#     print(np.unique(pred.cpu().detach().numpy(),return_counts=True))\n",
    "    return pred, uncert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554d9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "metrics = list()\n",
    "batch = next(iter(test_loader))\n",
    "x,y = batch['x'].cuda(), batch['y'].cuda()\n",
    "\n",
    "def predictor(x, return_idx=0): # in case of prediction is type of list\n",
    "    net.eval()\n",
    "    result = net(x)\n",
    "    if isinstance(result, list) or isinstance(result, tuple):\n",
    "        return result[return_idx]\n",
    "    else:\n",
    "        return result\n",
    "# yhat,uncert = bayesian_inference_seg(net, x, iteration=2)\n",
    "roi_size=320\n",
    "yhat = sliding_window_inference(inputs=x, roi_size=roi_size, sw_batch_size=4, predictor=predictor, overlap=0.75, mode='constant')\n",
    "# print(metric(yhat,y))\n",
    "show_batch_samples(x,y,yhat)\n",
    "        \n",
    "# metrics = torch.tensor(metrics)\n",
    "# print(torch.mean(metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e1d46-b3ce-434b-b268-7f60f0e58a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9936580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.inferers import sliding_window_inference\n",
    "\n",
    "metrics = list()\n",
    "for idx,batch in enumerate(test_loader):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        x,y = batch['x'].cuda(), batch['y'].cuda()\n",
    "        yhat,uncert = bayesian_inference_seg(net, x, iteration=20)\n",
    "#         plt.figure(figsize=(24,16))\n",
    "#         plt.subplot(131)\n",
    "#         plt.imshow(x[0,0].cpu().detach(),cmap='gray')\n",
    "#         plt.subplot(132)\n",
    "#         plt.imshow(yhat[0,0].cpu().detach(),cmap='gray')\n",
    "#         plt.subplot(133)\n",
    "#         plt.imshow(uncert[0].cpu().detach(),cmap='gray')\n",
    "#         plt.show()\n",
    "\n",
    "        metrics.append(metric(yhat,y))\n",
    "        print(metric(yhat,y))\n",
    "        show_batch_samples(x,y,yhat)\n",
    "        \n",
    "metrics = torch.tensor(metrics)\n",
    "print(torch.mean(metrics))\n",
    "\n",
    "# .1 tensor([[0.8290]], device='cuda:0')\n",
    "# .2 tensor([[0.8299]], device='cuda:0')\n",
    "# .3 tensor([[0.8289]], device='cuda:0')\n",
    "# tensor(0.8135) with out tophat\n",
    "\n",
    "# yhat = bayesian_inference_seg(net, x, iteration=20, vote_threshold=0.2, tophat_param=7) tensor(0.7921)\n",
    "# yhat = bayesian_inference_seg(net, x, iteration=20, vote_threshold=0.2, tophat_param=9) tensor(0.8121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import monai\n",
    "# from monai.inferers import sliding_window_inference\n",
    "\n",
    "# batch = next(iter(test_loader))\n",
    "# x,y = batch['x'].cuda(), batch['y'].cuda()\n",
    "# yhat = bayesian_inference_seg(net,x,iteration=20, vote_threshold=0.1, tophat_param=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066034c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric(torch.argmax(yhat[0],1).unsqueeze(1),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1239eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yhat[1].cpu().detach().numpy().flatten(),bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(yhat[1]),torch.max(yhat[1]),torch.std(yhat[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac883020",
   "metadata": {},
   "outputs": [],
   "source": [
    "-torch.mean(yhat[1])+torch.std(yhat[1])*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea556fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat[0].shape,yhat[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8087b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(yhat[1][0].cpu().detach().numpy())\n",
    "# torch.unique(yhat_matmul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c703df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat_matmul = (1-torch.argmax(yhat[0],1))*yhat[1]\n",
    "yhat_matmul = (torch.argmax(yhat[0],1))*yhat[1]\n",
    "# yhat_matmul = yhat[1]\n",
    "print(torch.unique(yhat_matmul))\n",
    "# yhat_matmul[yhat_matmul!=0] = 1\n",
    "# yhat_matmul[yhat_matmul<torch.std(yhat[1])] = 0\n",
    "yhat_matmul[yhat_matmul<torch.mean(yhat[1])] = 0\n",
    "yhat_matmul[yhat_matmul!=0] = 1\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(yhat_matmul[0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ab6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,24))\n",
    "plt.subplot(141)\n",
    "plt.imshow(y[0][0].cpu().detach().numpy())\n",
    "plt.subplot(142)\n",
    "# plt.imshow(yhat[0][0].cpu().detach().numpy())\n",
    "plt.imshow(yhat[0][0][1].cpu().detach().numpy())\n",
    "plt.subplot(143)\n",
    "uncent = yhat[1][0].cpu().detach().numpy()\n",
    "uncent[uncent<0.0001] = 0\n",
    "uncent[uncent!=0] = 1\n",
    "plt.imshow(uncent)\n",
    "plt.subplot(144)\n",
    "final = yhat[0][0][1].cpu().detach().numpy()+yhat[1][0].cpu().detach().numpy()\n",
    "final[final<0.001] = 0\n",
    "final[final!=0] = 1\n",
    "plt.imshow(x[0].permute(1,2,0).cpu().detach().numpy())\n",
    "plt.imshow(final,alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70cc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,24))\n",
    "plt.imshow(uncent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5895f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.test(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5840e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = trainer.predict(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8998efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils \n",
    "for output in outputs:\n",
    "    x,y,yhat = output['x'],output['y'],output['yhat']\n",
    "    yhat = utils.Activation(yhat)\n",
    "    plt.figure(figsize=(25,25))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(x[0].permute(1,2,0).cpu().detach().numpy())\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(y[0,0].cpu().detach().numpy())\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(yhat[0,1].cpu().detach().numpy())\n",
    "#     plt.subplot(144)\n",
    "#     plt.imshow(torch.argmax(yhat,1)[0].cpu().detach().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa8fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()\n",
    "a= torch.rand(2,3,128,128).cuda()\n",
    "b = net(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110e40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x = batch['x']\n",
    "plt.imshow(x[0,0])\n",
    "plt.show()\n",
    "plt.imshow(x[0,1])\n",
    "plt.show()\n",
    "plt.imshow(x[0,2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c3dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pylab as plt\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "for idx, batch in enumerate(test_loader):\n",
    "    x,y = batch['x'].to(device), batch['y'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        def predictor(x, return_idx=0): # in case of prediction is type of list\n",
    "            result = net(x)\n",
    "            if isinstance(result, list) or isinstance(result, tuple):\n",
    "                return result[return_idx]\n",
    "            else:\n",
    "                return result\n",
    "\n",
    "        roi_size = 128\n",
    "        yhat = sliding_window_inference(inputs=x, roi_size=roi_size,sw_batch_size=4,predictor=predictor,overlap=0.75,mode='constant')\n",
    "        yhat = utils.Activation(yhat)\n",
    "\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(x[0].cpu().detach().permute(1,2,0))\n",
    "        plt.imshow(y[0,0].cpu().detach(),alpha=0.5,cmap='gray')\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(torch.argmax(yhat,1)[0].cpu().detach(),cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94bfb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.imshow(x[0].permute(1,2,0))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.imshow(x[0].permute(1,2,0))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "# !pip install -r requirements.txt --user --quiet -U\n",
    "!pip uninstall torch -y\n",
    "!pip install torch==1.8.0\n",
    "# !apt updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2718cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo apt update\n",
    "# !sudo apt install libgl1-mesa-glx ffmpeg libsm6 libxext6 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1b5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "net = smp.Unet()\n",
    "# net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "w=pywt.Wavelet('db1')\n",
    "# w=pywt.Wavelet('haar')\n",
    "# w=pywt.Wavelet('rbio1.1')\n",
    "dec_hi = torch.Tensor(w.dec_hi[::-1]) \n",
    "dec_lo = torch.Tensor(w.dec_lo[::-1])\n",
    "rec_hi = torch.Tensor(w.rec_hi)\n",
    "rec_lo = torch.Tensor(w.rec_lo)\n",
    "\n",
    "filters = torch.stack([dec_lo.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                       dec_lo.unsqueeze(0)*dec_hi.unsqueeze(1),\n",
    "                       dec_hi.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                       dec_hi.unsqueeze(0)*dec_hi.unsqueeze(1)], dim=0)\n",
    "inv_filters = torch.stack([rec_lo.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                           rec_lo.unsqueeze(0)*rec_hi.unsqueeze(1),\n",
    "                           rec_hi.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                           rec_hi.unsqueeze(0)*rec_hi.unsqueeze(1)], dim=0)\n",
    "\n",
    "filters = torch.stack([dec_lo.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                       dec_lo.unsqueeze(0)*dec_hi.unsqueeze(1),\n",
    "                       dec_hi.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                       dec_hi.unsqueeze(0)*dec_hi.unsqueeze(1)], dim=0)\n",
    "inv_filters = torch.stack([rec_lo.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                           rec_lo.unsqueeze(0)*rec_hi.unsqueeze(1),\n",
    "                           rec_hi.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                           rec_hi.unsqueeze(0)*rec_hi.unsqueeze(1)], dim=0)\n",
    "\n",
    "def wt(vimg):\n",
    "    padded = vimg\n",
    "    res = torch.zeros(vimg.shape[0],4*vimg.shape[1],int(vimg.shape[2]/2),int(vimg.shape[3]/2))\n",
    "    res = res.cuda()\n",
    "    for i in range(padded.shape[1]):\n",
    "        res[:,4*i:4*i+4] = torch.nn.functional.conv2d(padded[:,i:i+1], Variable(filters[:,None].cuda(),requires_grad=True),stride=2)\n",
    "#         res[:,4*i+1:4*i+4] = (res[:,4*i+1:4*i+4]+1)/2.0\n",
    "    return res\n",
    "\n",
    "def iwt(vres):\n",
    "    res = torch.zeros(vres.shape[0],int(vres.shape[1]/4),int(vres.shape[2]*2),int(vres.shape[3]*2))\n",
    "    res = res.cuda()\n",
    "    for i in range(res.shape[1]):\n",
    "#         vres[:,4*i+1:4*i+4]=2*vres[:,4*i+1:4*i+4]-1\n",
    "        temp = torch.nn.functional.conv_transpose2d(vres[:,4*i:4*i+4], Variable(inv_filters[:,None].cuda(),requires_grad=True),stride=2)\n",
    "        res[:,i:i+1,:,:] = temp\n",
    "    return res\n",
    "import torch.nn as nn\n",
    "\n",
    "class WT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WT,self).__init__()\n",
    "        \n",
    "        w=pywt.Wavelet('db1')\n",
    "        # w=pywt.Wavelet('haar')\n",
    "        # w=pywt.Wavelet('rbio1.1')\n",
    "        dec_hi = torch.Tensor(w.dec_hi[::-1]) \n",
    "        dec_lo = torch.Tensor(w.dec_lo[::-1])\n",
    "        rec_hi = torch.Tensor(w.rec_hi)\n",
    "        rec_lo = torch.Tensor(w.rec_lo)\n",
    "\n",
    "        self.filters = torch.stack([dec_lo.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                               dec_lo.unsqueeze(0)*dec_hi.unsqueeze(1),\n",
    "                               dec_hi.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                               dec_hi.unsqueeze(0)*dec_hi.unsqueeze(1)], dim=0)\n",
    "        self.inv_filters = torch.stack([rec_lo.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                                   rec_lo.unsqueeze(0)*rec_hi.unsqueeze(1),\n",
    "                                   rec_hi.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                                   rec_hi.unsqueeze(0)*rec_hi.unsqueeze(1)], dim=0)\n",
    "\n",
    "#         filters = torch.stack([dec_lo.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "#                                dec_lo.unsqueeze(0)*dec_hi.unsqueeze(1),\n",
    "#                                dec_hi.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "#                                dec_hi.unsqueeze(0)*dec_hi.unsqueeze(1)], dim=0)\n",
    "#         inv_filters = torch.stack([rec_lo.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "#                                    rec_lo.unsqueeze(0)*rec_hi.unsqueeze(1),\n",
    "#                                    rec_hi.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "#                                    rec_hi.unsqueeze(0)*rec_hi.unsqueeze(1)], dim=0)\n",
    "    def forward(self,vimg):\n",
    "        print(vimg.shape)\n",
    "        padded = vimg\n",
    "        res = torch.zeros(vimg.shape[0],4*vimg.shape[1],int(vimg.shape[2]/2),int(vimg.shape[3]/2))\n",
    "        res = res.cuda()\n",
    "        for i in range(padded.shape[1]):\n",
    "            res[:,4*i:4*i+4] = torch.nn.functional.conv2d(padded[:,i:i+1], Variable(self.filters[:,None].cuda(),requires_grad=True),stride=2)            \n",
    "    #         res[:,4*i+1:4*i+4] = (res[:,4*i+1:4*i+4]+1)/2.0\n",
    "        filters = torch.zeros(vimg.shape[1],4*vimg.shape[1],int(vimg.shape[2]/2),int(vimg.shape[3]/2))\n",
    "        print(res.shape,filters.shape)\n",
    "        res = torch.nn.functional.conv2d(res,Variable(filters.cuda(),requires_grad=True),stride=1)\n",
    "        return res\n",
    "    \n",
    "class IWT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IWT,self).__init__()\n",
    "        \n",
    "        w=pywt.Wavelet('db1')\n",
    "        # w=pywt.Wavelet('haar')\n",
    "        # w=pywt.Wavelet('rbio1.1')\n",
    "        dec_hi = torch.Tensor(w.dec_hi[::-1]) \n",
    "        dec_lo = torch.Tensor(w.dec_lo[::-1])\n",
    "        rec_hi = torch.Tensor(w.rec_hi)\n",
    "        rec_lo = torch.Tensor(w.rec_lo)\n",
    "\n",
    "        filters = torch.stack([dec_lo.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                               dec_lo.unsqueeze(0)*dec_hi.unsqueeze(1),\n",
    "                               dec_hi.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                               dec_hi.unsqueeze(0)*dec_hi.unsqueeze(1)], dim=0)\n",
    "        inv_filters = torch.stack([rec_lo.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                                   rec_lo.unsqueeze(0)*rec_hi.unsqueeze(1),\n",
    "                                   rec_hi.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                                   rec_hi.unsqueeze(0)*rec_hi.unsqueeze(1)], dim=0)\n",
    "\n",
    "        filters = torch.stack([dec_lo.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                               dec_lo.unsqueeze(0)*dec_hi.unsqueeze(1),\n",
    "                               dec_hi.unsqueeze(0)*dec_lo.unsqueeze(1),\n",
    "                               dec_hi.unsqueeze(0)*dec_hi.unsqueeze(1)], dim=0)\n",
    "        inv_filters = torch.stack([rec_lo.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                                   rec_lo.unsqueeze(0)*rec_hi.unsqueeze(1),\n",
    "                                   rec_hi.unsqueeze(0)*rec_lo.unsqueeze(1),\n",
    "                                   rec_hi.unsqueeze(0)*rec_hi.unsqueeze(1)], dim=0)\n",
    "    def forward(self,vres):\n",
    "        res = torch.zeros(vres.shape[0],int(vres.shape[1]/4),int(vres.shape[2]*2),int(vres.shape[3]*2))\n",
    "        res = res.cuda()\n",
    "        for i in range(res.shape[1]):\n",
    "    #         vres[:,4*i+1:4*i+4]=2*vres[:,4*i+1:4*i+4]-1\n",
    "            temp = torch.nn.functional.conv_transpose2d(vres[:,4*i:4*i+4], Variable(inv_filters[:,None].cuda(),requires_grad=True),stride=2)\n",
    "            res[:,i:i+1,:,:] = temp\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391da217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "net = smp.Unet(in_channels=4).cuda()\n",
    "\n",
    "def maxpool2wt(module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.modules.MaxPool2d):\n",
    "        module_output = WT()\n",
    "        \n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(name, maxpool2wt(child))\n",
    "\n",
    "    del module\n",
    "    return module_output\n",
    "\n",
    "def upsample2iwt(module):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.functional.interpolate):\n",
    "        module_output = IWT()\n",
    "        \n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(name, upsample2iwt(child))\n",
    "\n",
    "    del module\n",
    "    return module_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9724589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand(1,4,64,64).cuda()\n",
    "b= net(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f2bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ = maxpool2wt(net)\n",
    "net_ = net_.cuda()\n",
    "net_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76abd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand(2,4,64,64).cuda()\n",
    "b= net_(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ =upsample2iwt(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a038e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
