{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov 20 13:13:57 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 53%   69C    P0    60W / 250W |      0MiB / 12194MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN X (Pascal)    Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 49%   81C    P2    88W / 250W |   6599MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN X (Pascal)    Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 46%   79C    P2    86W / 250W |   5651MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN X (Pascal)    Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 31%   48C    P0    58W / 250W |      0MiB / 12196MiB |      3%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "True\n",
      "1\n",
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorboard==1.15\n",
    "!nvidia-smi\n",
    "gpus= \"0\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus;\n",
    "\n",
    "import torch\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(torch.cuda.is_available())\n",
    "print(gpu_count)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPlbdmG5UAGx"
   },
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aIzLl9gbUAGz",
    "outputId": "4cfed527-4030-4a52-9d3f-98fd0290e80d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -q \"monai[nibabel, tensorboard]\"\n",
    "!pip install -q \"monai[ignite, nibabel, tqdm]\" --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U git+https://github.com/Project-MONAI/MONAI#egg=MONAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DknVfZCgUAHA",
    "outputId": "6b10bb72-2aac-4a4e-e7de-9b4f7ade0d8d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # %pip install -q pytorch-lightning==0.9.0\n",
    "# # %pip uninstall -y pytorch-lightning\n",
    "# !sudo pip install pytorch-lightning==1.0.3 \n",
    "# # !pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade\n",
    "# # psutil\n",
    "# # !pip install neptune-client --quiet \n",
    "# !sudo pip install monai\n",
    "# # pytorch_lightning.__version__,monai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7DbmSpjUAHW"
   },
   "source": [
    "## Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aR643O-eUAHW",
    "outputId": "807d8218-6c65-4eb9-fef2-039e83c3e46e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 0.3.0\n",
      "Python version: 3.6.8 (default, Jan 14 2019, 11:02:34)  [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]]\n",
      "OS version: Linux (5.4.0-52-generic)\n",
      "Numpy version: 1.19.4\n",
      "Pytorch version: 1.7.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.2\n",
      "Nibabel version: 3.2.0\n",
      "scikit-image version: 0.17.2\n",
      "Pillow version: 8.0.1\n",
      "Tensorboard version: 2.3.0\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.8.1\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.51.0\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning\n",
    "import torch\n",
    "\n",
    "import monai\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import CacheDataset, list_data_collate\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceLoss,TverskyLoss,FocalLoss,GeneralizedDiceLoss\n",
    "from monai.metrics import compute_meandice\n",
    "from monai.networks.layers import Norm\n",
    "from monai.networks.nets import *\n",
    "from monai.transforms import *\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.data import Dataset, CacheDataset, DataLoader, create_test_image_3d\n",
    "from monai.engines import EnsembleEvaluator, SupervisedEvaluator, SupervisedTrainer\n",
    "from monai.handlers import MeanDice, StatsHandler, ValidationHandler\n",
    "from monai.inferers import SimpleInferer, SlidingWindowInferer\n",
    "from monai.losses import DiceLoss\n",
    "from monai.networks.nets import UNet, VNet, HighResNet\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path_train = 'Train/'\n",
    "\n",
    "x_train = sorted(glob.glob(path_train+\"*ct*\"))\n",
    "y_train = sorted(glob.glob(path_train+\"*seg*\"))\n",
    "path_test = 'Validation/'\n",
    "\n",
    "x_test = sorted(glob.glob(path_test+\"*ct*\"))\n",
    "y_test = sorted(glob.glob(path_test+\"*seg*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_normal = sorted(glob.glob(path_train+\"*normal_image*\"))\n",
    "# x_cyst = sorted(glob.glob(path_train+\"*cyst_image*\"))\n",
    "# x_cancer = sorted(glob.glob(path_train+\"*Cancer_image*\"))\n",
    "# x_SPN = sorted(glob.glob(path_train+\"*SPN_image*\"))\n",
    "# x_NET = sorted(glob.glob(path_train+\"*NET_image*\"))\n",
    "\n",
    "# y_normal = sorted(glob.glob(path_train+\"*normal_seg*\"))\n",
    "# y_cyst = sorted(glob.glob(path_train+\"*cyst_seg*\"))\n",
    "# y_cancer = sorted(glob.glob(path_train+\"*Cancer_seg*\"))\n",
    "# y_SPN = sorted(glob.glob(path_train+\"*SPN_seg*\"))\n",
    "# y_NET = sorted(glob.glob(path_train+\"*NET_seg*\"))\n",
    "\n",
    "# print(len(x_normal),len(x_cyst),len(x_cancer),len(x_SPN),len(x_NET))\n",
    "# print(len(y_normal),len(y_cyst),len(y_cancer),len(y_SPN),len(y_NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Keeplearning.load_data import *\n",
    "# import tqdm\n",
    "# spacings = []\n",
    "# for idx in tqdm.tqdm(range(len(x_train))):\n",
    "#     image, origin, spacing = data_load_nii_withSITK(x_train[idx],return_info=True)\n",
    "#     spacings.append(spacing)\n",
    "\n",
    "# spacings = np.array(spacings)\n",
    "# spacings[:,0].mean(),spacings[:,1].mean(),spacings[:,2].mean()\n",
    "# # (0.40741928562001306, 0.40741928562001306, 4.840921944104015)\n",
    "\n",
    "# np.median(spacings[:,0]),np.median(spacings[:,1]),np.median(spacings[:,2])\n",
    "# (.67, .67, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "folds = 5\n",
    "kf = KFold(n_splits=folds,shuffle=True,random_state=0)\n",
    "kf.get_n_splits(x_train)\n",
    "\n",
    "train_files = list()\n",
    "val_files = list()\n",
    "\n",
    "for train_index, val_index in kf.split(x_train):\n",
    "    \n",
    "    FOLDS_train_image = list()\n",
    "    FOLDS_train_seg = list()\n",
    "    FOLDS_val_image = list()\n",
    "    FOLDS_val_seg = list()\n",
    "\n",
    "    for idx in train_index:\n",
    "        FOLDS_train_image.append(x_train[idx])\n",
    "        FOLDS_train_seg.append(y_train[idx])\n",
    "        \n",
    "    for idx in val_index:\n",
    "        FOLDS_val_image.append(x_train[idx])\n",
    "        FOLDS_val_seg.append(y_train[idx])\n",
    "    \n",
    "    train_files.append(\n",
    "        [\n",
    "            {\"image\": img, \"label\": seg} for img, seg in zip(FOLDS_train_image,FOLDS_train_seg)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    val_files.append(\n",
    "        [\n",
    "             {\"image\": img, \"label\": seg} for img, seg in zip(FOLDS_val_image,FOLDS_val_seg)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "test_files = [{\"image\": img, \"label\": seg} for img, seg in zip(x_test,y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_files = [{\"image\": img, \"label\": seg} for img, seg in zip(x_train,y_train)]\n",
    "# val_files = [{\"image\": img, \"label\": seg} for img, seg in zip(x_valid,y_valid)]\n",
    "# test_files = [{\"image\": img, \"label\": seg} for img, seg in zip(x_test,y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_determinism(seed=0)\n",
    "\n",
    "patch_size = (256,256,16)\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),\n",
    "        RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[0,1], prob=0.3),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(.74, .74), mode=(\"bilinear\", \"nearest\")),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(.74, .74, 5.0), mode=(\"nearest\", \"nearest\")),\n",
    "        RandRotate90d(keys=[\"image\", \"label\"], prob=0.3, spatial_axes=[0, 1]),\n",
    "        \n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-1000.0, a_max=500.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "#         ScaleIntensityRanged(keys=[\"image\"], a_min=30-500/2, a_max=30+500/2, b_min=0.0, b_max=1.0, clip=True),\n",
    "#         ScaleIntensityRanged(keys=[\"label\"], a_min=0, a_max=3, b_min=0, b_max=3, clip=True),\n",
    "        \n",
    "        RandAdjustContrastd(keys=[\"image\"],gamma=(0.5, 1.5), prob=0.1),\n",
    "        RandShiftIntensityd(keys=[\"image\"],offsets= (-0.03, 0.03), prob=0.1),\n",
    "        RandScaleIntensityd(keys=[\"image\"],factors= (0,0.1), prob=0.1),\n",
    "        RandGaussianSmoothd(keys=[\"image\"],sigma_x=(0, 0.1), sigma_y=(0, 0.11), sigma_z=(0, 0.001), prob=0.1),\n",
    "        RandHistogramShiftd(keys=[\"image\"],num_control_points=(10,20), prob=0.1),        \n",
    "        RandAdjustContrastd(keys=[\"image\"],gamma=(0.5, 1.5), prob=0.1),\n",
    "\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=patch_size,\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "        ),\n",
    "#         RandZoomd(\n",
    "#             keys=[\"image\", \"label\"],\n",
    "#             min_zoom=0.9,\n",
    "#             max_zoom=1.2,\n",
    "#             mode=(\"trilinear\", \"nearest\"),\n",
    "#             align_corners=(True, None),\n",
    "#             prob=0.16,\n",
    "#         ),\n",
    "        CastToTyped(keys=[\"image\", \"label\"], dtype=(np.float32, np.uint8)),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadNiftid(keys=[\"image\", \"label\"]),\n",
    "        AddChanneld(keys=[\"image\", \"label\"]),              \n",
    "#         Spacingd(keys=[\"image\", \"label\"], pixdim=(.67, .67), mode=(\"bilinear\", \"nearest\")),\n",
    "#         Spacingd(keys=[\"image\", \"label\"], pixdim=(.67, .67, 3.0), mode=(\"nearest\", \"nearest\")),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(.74, .74), mode=(\"bilinear\", \"nearest\")),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(.74, .74, 5.0), mode=(\"nearest\", \"nearest\")),\n",
    "        \n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=-1000.0, a_max=500.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "#         ScaleIntensityRanged(keys=[\"image\"], a_min=30-500/2, a_max=30+500/2, b_min=0.0, b_max=1.0, clip=True),\n",
    "#         ScaleIntensityRanged(keys=[\"label\"], a_min=0, a_max=3, b_min=0, b_max=3, clip=True),\n",
    "        CastToTyped(keys=[\"image\", \"label\"], dtype=(np.float32, np.uint8)),\n",
    "        ToTensord(keys=[\"image\", \"label\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "\n",
    "set_determinism(seed=0)\n",
    "\n",
    "train_dss = [Dataset(data=train_files[i], transform=train_transforms) for i in range(folds)]\n",
    "train_loaders = [DataLoader(train_dss[i], batch_size=4*gpu_count, shuffle=True, num_workers=4) for i in range(folds)]\n",
    "val_dss = [Dataset(data=val_files[i], transform=val_transforms) for i in range(folds)]\n",
    "val_loaders = [DataLoader(val_dss[i], batch_size=1, num_workers=4) for i in range(folds)]\n",
    "\n",
    "train_ds = Dataset(data=train_files[fold], transform=train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=2*gpu_count, shuffle=True, num_workers=2)\n",
    "val_ds = Dataset(data=val_files[fold], transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=2)\n",
    "test_ds = Dataset(data=test_files, transform=val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Datasets(nn.Module):\n",
    "#     def __init__(self,data,transform):\n",
    "#         self.data = data\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self,idx):\n",
    "#         sample = self.data[idx]\n",
    "#         sample = self.transform(sample)\n",
    "#         try:\n",
    "#             sample = sample[0]\n",
    "#         except:\n",
    "#             pass\n",
    "#         if len(torch.unique(sample['seg']))>1:\n",
    "#             sample['cls'] = torch.tensor([1])\n",
    "#         else:\n",
    "#             sample['cls'] = torch.tensor([0])\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # batch = next(iter(test_loader))\n",
    "# batch = train_ds[0]\n",
    "\n",
    "# image = batch['image']\n",
    "# seg = batch['label']\n",
    "\n",
    "# positive = 0\n",
    "# negative = 0\n",
    "\n",
    "# for idx in range(len(seg)):\n",
    "#     print(idx, torch.unique(seg[idx]))\n",
    "#     if len(torch.unique(seg[idx]))>1:\n",
    "#         positive += 1\n",
    "#     else: \n",
    "#         negative += 1\n",
    "    \n",
    "# print(positive,negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# image = batch[idx]['image']\n",
    "# seg = batch[idx]['label']\n",
    "# print(torch.unique(image),torch.unique(seg))\n",
    "\n",
    "# for idx in range(image.shape[-1]):\n",
    "#     plt.figure()\n",
    "#     plt.title(idx)\n",
    "#     plt.imshow(image[0,...,idx],cmap='gray')\n",
    "#     plt.imshow(seg[0,...,idx],alpha=0.3)\n",
    "# #     print(torch.unique(image[0,...,idx]),torch.unique(seg[0,...,idx]))#,cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.loss = nn.CrossEntropyLoss(weight=torch.tensor([.1,.2,.4,.4]))\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # CrossEntropyLoss target needs to have shape (B, D, H, W)\n",
    "        # Target from pipeline has shape (B, C, D, H, W)\n",
    "        y_true = torch.squeeze(y_true, dim=1).long()\n",
    "#         print(y_pred.shape,y_true.shape)\n",
    "        return self.loss(y_pred, y_true)\n",
    "    \n",
    "class DiceCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dice = GeneralizedDiceLoss(to_onehot_y=True, softmax=True)\n",
    "        self.cross_entropy = CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        dice = self.dice(y_pred, y_true)\n",
    "        cross_entropy = self.cross_entropy(y_pred, y_true)\n",
    "        return dice + cross_entropy    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import *\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_metric = list()\n",
    "    step = 0\n",
    "    \n",
    "    for batch_data in tqdm.tqdm(train_loader):\n",
    "        step += 1\n",
    "        inputs, labels = batch_data['image'].to(device), batch_data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        if amp and scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / step\n",
    "\n",
    "def valid():\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0\n",
    "    metric = 0.\n",
    "    step = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_data in tqdm.tqdm(val_loader):  \n",
    "            step += 1              \n",
    "            inputs, labels = val_data['image'].to(device), val_data['label'].to(device)\n",
    "            roi_size = patch_size\n",
    "            sw_batch_size = 2\n",
    "            if amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = sliding_window_inference(inputs, roi_size, sw_batch_size, model)\n",
    "            else:\n",
    "                outputs = sliding_window_inference(inputs, roi_size, sw_batch_size, model)\n",
    "\n",
    "            loss = loss_function(outputs, labels)\n",
    "#             value = compute_meandice(y_pred=outputs, y=labels, include_background=False, to_onehot_y=True, mutually_exclusive=True)\n",
    "\n",
    "            epoch_val_loss += loss.item()\n",
    "#             metric += value.sum().item()\n",
    "            \n",
    "    return epoch_val_loss / step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "amp=True\n",
    "scaler = torch.cuda.amp.GradScaler() if amp else None\n",
    "\n",
    "epoch_num = 300\n",
    "lr = 1e-4\n",
    "\n",
    "# model & gpu setting\n",
    "device = torch.device('cuda')\n",
    "model = UNet(dimensions=3, in_channels=1, out_channels=2, channels=(16, 32, 64, 128, 256), strides=(2, 2, 2, 2), num_res_units=2, norm=Norm.BATCH)\n",
    "# model = VNet(spatial_dims=3, in_channels=1, out_channels=4)\n",
    "# model = monai.networks.nets.SegResNetVAE(patch_size, vae_estimate_std=True, vae_nz=256, spatial_dims=3, init_filters=8, in_channels=1, out_channels=4, dropout_prob=None, norm_name='group', num_groups=8, use_conv_final=True, blocks_down=(1, 2, 2, 4), blocks_up=(1, 1, 1), upsample_mode='nontrainable')\n",
    "\n",
    "model_w = torch.load(str(fold)+'best_unet.pth')\n",
    "model.load_state_dict(model_w)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "model= model.to(device)\n",
    "\n",
    "# loss & optimizer setting\n",
    "loss_function = DiceCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "optimizer = monai.optimizers.Novograd(model.parameters(), lr*3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,epoch_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install livelossplot --quiet\n",
    "import numpy as np\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "groups = {'log-loss': ['train_loss', 'val_loss']}\n",
    "plotlosses = PlotLosses(groups=groups)\n",
    "\n",
    "epoch_loss_values = list()\n",
    "epoch_val_loss_values = list()\n",
    "epoch_metric_values = list()\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print('fold       {} / {}  '.format(fold,folds))\n",
    "    print('epoch     ',epoch)\n",
    "    print('train     ', epoch_loss_values)\n",
    "    print('validation', epoch_val_loss_values)\n",
    "    epoch_loss = train()\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    \n",
    "    epoch_val_loss = valid()\n",
    "    epoch_val_loss_values.append(epoch_val_loss)\n",
    "    \n",
    "    if epoch >= 3 and epoch_val_loss == np.min(epoch_val_loss_values):\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            torch.save(model.module.state_dict(),str(fold)+'best_unet.pth')\n",
    "        else:\n",
    "            torch.save(model.state_dict(), str(fold)+'best_unet.pth')\n",
    "        print('saved new best metric model')\n",
    "    \n",
    "    plotlosses.update({\n",
    "    'train_loss': epoch_loss,\n",
    "    'val_loss': epoch_val_loss\n",
    "    })\n",
    "    plotlosses.send()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(fold)+'best_unet.pth')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    torch.save(model.module.state_dict(),str(fold)+'best_unet.pth')\n",
    "else:\n",
    "    torch.save(model.state_dict(), str(fold)+'best_unet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pr = torch.rand(2,4,64,64,64)\n",
    "# gt = torch.randint(0,4,(2,64,64,64))\n",
    "\n",
    "# pr = torch.log_softmax(pr, dim=1)\n",
    "# temp = torch.argmax(pr, dim =1)\n",
    "\n",
    "# for idx in range(2):\n",
    "#     pr_ = temp[idx]\n",
    "#     gt_ = gt[idx]\n",
    "\n",
    "#     pr_[pr_==2] = 0\n",
    "#     gt_[gt_==2] = 0\n",
    "#     gt_[gt_==3] = 0\n",
    "#     print(pr.shape,torch.unique(pr_),gt.shape,torch.unique(gt_))\n",
    "\n",
    "#     dice = f1_score(gt_.flatten(),pr_.flatten(),average=None)\n",
    "#     print(dice)\n",
    "\n",
    "# def metric_f1(pr,gt):\n",
    "#     \"\"\"\n",
    "#     pr : shape (N,C,H,W,(D))\n",
    "#     gt : shape (N,H,W,(D))\n",
    "#     \"\"\"\n",
    "    \n",
    "#     N = pr.shape[0]\n",
    "#     C = pr.shape[1]\n",
    "#     assert C > 1\n",
    "    \n",
    "#     pr = torch.log_softmax(pr, dim=1)\n",
    "#     pr = torch.argmax(pr, dim=1)\n",
    "    \n",
    "#     result = torch.zeros(N,C)\n",
    "    \n",
    "#     for idx in range(N):\n",
    "#         pr_ = pr[idx]\n",
    "#         gt_ = gt[idx]\n",
    "        \n",
    "#         pr_[pr_==2] = 0\n",
    "#         gt_[gt_==2] = 0\n",
    "#         gt_[gt_==3] = 0\n",
    "#         print(pr.shape,torch.unique(pr_),gt.shape,torch.unique(gt_))\n",
    "  \n",
    "# #         dice = f1_score(gt_.cpu().detach().numpy().flatten(),pr_.cpu().detach().numpy().flatten(),average=None)\n",
    "#         dice = f1_score(gt_.flatten(),pr_.flatten(),average=None)\n",
    "#         print(dice)\n",
    "#     return result\n",
    "\n",
    "# metric_f1(pr,gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w = torch.load(str(fold)+'best_unet.pth')\n",
    "model.load_state_dict(model_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 513, 513, 73]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 585, 585, 61]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 638, 638, 54]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 513, 513, 73]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 651, 651, 55]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 599, 599, 77]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 520, 520, 63]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 472, 472, 58]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 512, 512, 53]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 617, 617, 73]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 512, 512, 54]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 512, 512, 66]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 614, 614, 52]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 662, 662, 63]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 513, 513, 65]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 559, 559, 53]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 649, 649, 58]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 564, 564, 66]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 513, 513, 51]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 534, 534, 60]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 512, 512, 57]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 513, 513, 45]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 580, 580, 56]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 613, 613, 62]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 513, 513, 41]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 596, 596, 72]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 406, 406, 39]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 554, 554, 73]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 535, 535, 58]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 512, 512, 60]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 576, 576, 54]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 593, 593, 60]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 513, 513, 68]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 406, 406, 44]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 493, 493, 66]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 638, 638, 72]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 315, 315, 49]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 473, 473, 63]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 328, 328, 37]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n",
      "torch.Size([1, 1, 567, 567, 64]) tensor([0, 1], dtype=torch.uint8) tensor([0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, val_data in enumerate(val_loader):\n",
    "        image = val_data[\"image\"] \n",
    "        label = val_data[\"label\"]\n",
    "        fname_image = val_data[\"image_meta_dict\"]['filename_or_obj'][0]\n",
    "        fname_label = val_data[\"label_meta_dict\"]['filename_or_obj'][0]\n",
    "        affine = val_data[\"image_meta_dict\"]['affine'][0]\n",
    "        original_affine = val_data[\"image_meta_dict\"]['original_affine'][0]\n",
    "        spatial_shape = val_data[\"image_meta_dict\"]['spatial_shape'][0]\n",
    "        \n",
    "        roi_size = patch_size\n",
    "        sw_batch_size = 4\n",
    "        outputs = sliding_window_inference(val_data[\"image\"].to(device), roi_size, sw_batch_size, model, 0.5, 'gaussian')\n",
    "        outputs = torch.argmax(outputs, dim=1).unsqueeze(1)\n",
    "        print(label.shape,torch.unique(label),torch.unique(outputs))\n",
    "        \n",
    "#         # for color visualization\n",
    "#         label_ = label.clone()\n",
    "#         outputs_ = outputs.clone()\n",
    "#         for idx in range(2):\n",
    "#             label_[0,0,0,idx,:] = idx\n",
    "#             outputs_[0,0,0,idx,:] = idx\n",
    "        \n",
    "#         for idx in range(label.shape[-1]):\n",
    "#             if len(torch.unique(label[...,idx]))>=2:\n",
    "#                 plt.figure(\"check\", (18, 6))\n",
    "#                 plt.subplot(1, 3, 1)\n",
    "#                 plt.title(f\"{fname_image} {idx}\")\n",
    "#                 plt.imshow(image[0, 0, :, :, idx], cmap=\"gray\")\n",
    "#                 plt.subplot(1, 3, 2)\n",
    "#                 plt.title(f\"label {i}\")\n",
    "#                 plt.imshow(image[0, 0, :, :, idx], cmap=\"gray\")\n",
    "#                 plt.imshow(label_[0, 0, :, :, idx], alpha=0.5)\n",
    "#                 plt.subplot(1, 3, 3)\n",
    "#                 plt.title(f\"output {i}\")\n",
    "#                 plt.imshow(image[0, 0, :, :, idx], cmap=\"gray\")\n",
    "#                 plt.imshow(outputs_.detach().cpu()[0, 0,:, :,idx], alpha=0.5)\n",
    "#                 plt.show()                \n",
    "                \n",
    "        monai.data.write_nifti(data=image.cpu().detach().numpy().squeeze(),\n",
    "                               file_name='Output/'+str(fold)+'/'+fname_image.split('/')[-1],\n",
    "                               resample=True,\n",
    "                               affine=affine, \n",
    "                               mode=\"bilinear\",\n",
    "                               target_affine=original_affine,\n",
    "                               output_spatial_shape=spatial_shape)\n",
    "        \n",
    "        monai.data.write_nifti(data=outputs.cpu().detach().numpy().squeeze(),\n",
    "                               file_name='Output/'+str(fold)+'/'+fname_label.split('/')[-1],\n",
    "                               resample=True,\n",
    "                               affine=affine,\n",
    "                               mode=\"nearest\",\n",
    "                               target_affine=original_affine,\n",
    "                               output_spatial_shape=spatial_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models= [model,model,model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ensemble_evaluate(post_transforms, models):\n",
    "#     evaluator = EnsembleEvaluator(\n",
    "#         device=device,\n",
    "#         val_data_loader=test_loader,\n",
    "#         pred_keys=[\"pred0\", \"pred1\", \"pred2\", \"pred3\", \"pred4\"],\n",
    "#         networks=models,\n",
    "#         inferer=SlidingWindowInferer(roi_size=patch_size, sw_batch_size=4, overlap=0.5),\n",
    "#         post_transform=post_transforms,\n",
    "#         key_val_metric={\n",
    "#             \"test_mean_dice\": MeanDice(\n",
    "#                 include_background=True, to_onehot_y=True, output_transform=lambda x: (x[\"pred\"], x[\"label\"]),\n",
    "#             )\n",
    "#         },\n",
    "#     )\n",
    "#     evaluator.run()\n",
    "    \n",
    "# mean_post_transforms = Compose(\n",
    "#     [\n",
    "#         MeanEnsembled(\n",
    "#             keys=[\"pred0\", \"pred1\", \"pred2\", \"pred3\", \"pred4\"],\n",
    "#             output_key=\"pred\",\n",
    "#             # in this particular example, we use validation metrics as weights\n",
    "#             weights=[0.95, 0.94, 0.95, 0.94, 0.90],\n",
    "#         ),\n",
    "#         Activationsd(keys=\"pred\", sigmoid=True),\n",
    "#         AsDiscreted(keys=\"pred\", threshold_values=True),\n",
    "#     ]\n",
    "# )\n",
    "# ensemble_evaluate(mean_post_transforms, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AuwBUGxVUAHk"
   },
   "outputs": [],
   "source": [
    "from ignite.contrib.handlers import ProgressBar\n",
    "val_handlers = [\n",
    "    ProgressBar(),\n",
    "]\n",
    "\n",
    "def ensemble_evaluate(post_transforms, models):\n",
    "    evaluator = EnsembleEvaluator(\n",
    "        device=device,\n",
    "        val_data_loader=test_loader,\n",
    "        pred_keys=[\"pred0\", \"pred1\", \"pred2\"],\n",
    "        networks=models,\n",
    "        val_handlers=val_handlers,\n",
    "        inferer=SlidingWindowInferer(roi_size=patch_size, sw_batch_size=4, overlap=0.5),\n",
    "        post_transform=post_transforms,\n",
    "#         key_val_metric={\n",
    "#             \"test_mean_dice\": MeanDice(nclude_background=True, to_onehot_y=True, output_transform=lambda x: (x[\"pred\"], x[\"label\"]),\n",
    "#             )\n",
    "#         },\n",
    "    )\n",
    "    evaluator.run()\n",
    "    \n",
    "# mean_post_transforms = Compose(\n",
    "#     [\n",
    "#         MeanEnsembled(\n",
    "#             keys=[\"pred0\", \"pred1\", \"pred2\"],\n",
    "#             output_key=\"pred\",\n",
    "#             weights=[0.95, 0.94, 0.95],\n",
    "#         ),\n",
    "#         Activationsd(keys=\"pred\", softmax=True),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "mean_post_transforms = Compose(\n",
    "    [\n",
    "        VoteEnsembled(\n",
    "            keys=[\"pred0\", \"pred1\", \"pred2\"],\n",
    "            output_key=\"pred\",\n",
    "        ),\n",
    "        Activationsd(keys=\"pred\", softmax=True),\n",
    "    ]\n",
    ")\n",
    "pred = ensemble_evaluate(mean_post_transforms, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "spleen_segmentation_3d_lightning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
